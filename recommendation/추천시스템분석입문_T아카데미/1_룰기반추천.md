# 추천시스템

Rule 기반의 모델들

## 연관분석 (Association Analysis)

Rule 기반의 모델로서 상품과 상품 사이에 어떤 연관이 있는지 찾아내는 알고리즘이다. 어떤 상품들이 한 장바구니에 담기는지 살피는 모습과 비슷하여 장바구니 분석 이라고도 한다.

연관은 2가지 형태가 있다.

- 얼마나 같이 구매가 되는가? (빈도, frequent)
- A 아이템을 구매하는 사람이 B 아이템을 구매하는가?



ex) 월마트 맥주 - 기저귀 함께 진열



#### 연관분석 규칙 평가 지표

- 지지도(support)
  - support(A) = P(A)
- 신뢰도(confidence)
  - confidence(A -> B) = P(A, B) / P(A)
- 향상도(lift)
  - lift(A->B) = P(A, B) / ( P(A) * P(B) )
  - 두 사건이 동시에 얼마나 발생하는지 비율, 독립성을 측정.
  - 모델을 만들때는 지지도와 신뢰도 기반으로 하지만 세가지 지표를 적절하게 봐야한다.



#### 연관분석 규칙 생성

가능한 모든 경우의 수를 탐색해서 지지도, 신뢰도, 향상도가 높은 규칙들을 찾아내는 방식

상품이 4개일 때, 전체 경우의 수

- 4C1 : 4
- 4C2 : 6
- 4C3 : 4
- 4C4 : 1
- 전체 경우의 수 : 4 + 6 + 4 + 1 = 15



#### 연관분석 문제점

아이템의 증가에 따른 규칙의 수 또한 기하급수적으로 증가한다.

ex) 아이템 100개 -> 규칙의 수 1.26*10^30







## Apriori 알고리즘

아이템 셋의 증가를 줄이기 위한 방법이다.

"빈번한 아이템셋은 하위 아이템셋 또한 빈번할 것이다" 라는 아이디어.

"빈번하지 않은 아이템 셋은 하위 아이템셋 또한 빈번하지 않다" 를 이용해서 아이템셋의 증가를 줄이는 방법.



#### 알고리즘

1. k개의 item을 가지고 단일항목집단 생성 (one-item frequent set)
2. 단일항목집단에서 최소 지지도 (support) 이상의 항목만 성택
3. 2에서 선택된 항목만을 대상으로 2개항목집단 생성
4. 2개항목집단에서 최소 지지도 혹은 신뢰도 이상의 항목만 선택
5. 위의 과정을 k개의 k-item frequent set을 생성할 때까지 반복



#### Apriori 알고리즘 예시

데이터 (implicit Feedback)

implicit feedback: 사용자가 상품을 구매했지만 구매하고 만족했는지 불만족했는지에 대해서는 모른다.



| 거래번호 | 상품목록                   |
| -------- | -------------------------- |
| 0        | 우유, 기저귀, 쥬스         |
| 1        | 양상추, 기저귀, 맥주       |
| 2        | 우유, 양상추, 기저귀, 맥주 |
| 3        | 양상추, 맥주               |



| 거래번호 | 우유 | 양상추 | 기저귀 | 쥬스 | 맥주 |
| -------- | ---- | ------ | ------ | ---- | ---- |
| 0        | 1    | 0      | 1      | 1    | 0    |
| 1        | 0    | 1      | 1      | 0    | 1    |
| 2        | 1    | 1      | 1      | 0    | 1    |
| 3        | 0    | 1      | 0      | 0    | 1    |

1. 5개의 item을 가지고 단일항목집단 생성(one-item frequent set) : 우유, 양상추, 기저귀, 맥주, 쥬스
2. 단일항목집단에서 최소 지지도(support) 이상의 항목만 선택 (예: 최소지지도 0.5. 지지도 말고 신뢰도, 향상도로도 진행 가능, 함께 사용도 가능)
   - P(우유) : 0.5
   - P(양상추) : 0.75
   - P(기저귀) : 0.75
   - P(쥬스) : 0.25 (제거)
   - P(맥주) : 0.75
3. 2에서 선택된 항목만을 갖고 2개 항목 집단 생성
   - 우유, 양상추
   - 우유, 기저귀
   - 우유, 맥주
   - 양상추, 기저귀
   - 양상추, 맥주
   - 기저귀, 맥주
4. 2개항목집단에서 최소 지지도 이상의 항목만 선택
5. 위의 과정을 k개의 k-item frequent set을 생성할 때까지 반복
   - {우유}, {양상추}, {기저귀}, {맥주}
   - {우유, 기저귀}, {양상추, 기저귀}, {양상추, 맥주}, {기저귀, 맥주}
   - {양상추, 기저귀, 맥주}





#### 장점

- 원리가 간단하여 사용자가  쉽게 이해할 수 있고 의미를 파악할 수 있음
- 유의한 연관성을 갖는 구매패턴을 찾아줌

#### 단점

- 데이터가 클 경우 (item이 많은 경우)에 속도가 느리고 연산량이 많음
- 실제 사용시에 많은 연관상품들이 나타나는 단점이 있음





## FP-Growth 알고리즘

FP Growth는 Apriori의 속도측면의 단점을 개선한 알고리즘

Apriori와 비슷한 성능을 내지만 FP Tree라는 구조를 사용해서 빠른 속도를 가짐.

동일하게 발생하는 아이템 셋 (frequent itemsets)을 찾는데는 좋지만 아이템간의 연관성을 찾는 것은 어렵다.



#### 알고리즘

1. 모든 거래를 확인하여, 각 아이템마다의 지지도(support)를 계산하고 최소 지지도 이상의 아이템만 선택
2. 모든 거래에서 빈도가 높은 아이템 순서대로 순서를 정렬
3. 부모 노드를 중심으로 거래를 자식노드로 추가해주면서 tree 생성
4. 새로운 아이템이 나올 경우에는 부모노드부터 시작하고, 그렇지 않으면 기존의 노드에서 확장
5. 위의 과정을 모든 거래에 대해 반복하여 FP Tree를 만들고 지지도가 낮은 순서부터 시작하여, 모든 아이템의 조건부 패턴을 생성
6. 만들어진 조건부 패턴을 기반으로 패턴 생성



#### 장점:

- Apriori 알고리즘보다 빠르고 2번의 탐색만 필요로 함
- 후보 itemsets을 생성할 필요 없이 진행 가능

#### 단점:

- 대용량의 데이터셋에서 메모리를 효율적으로 사용하지 않음
- Apriori 알고리즘에 비해서 설계하기 어려움
- 지지도의 계산이 FP-Tree가 만들어지고 나서야 가능함.





```python
import mlxtend
import numpy as np
import pandas as pd

data = np.array([
    ['우유', '기저귀','주스'],
    ['양상추','기저귀','맥주'],
    ['우유','양상추','기저귀','맥주'],
    ['양상추','맥주']
])

# Apriori 알고리즘
from mlxtend.preprocessing import TransactionEncoder

te = TransactionEncoder()
te_ary = te.fit(data).transform(data)
df = pd.DataFrame(te_ary, columns=te.columns_)

%%time
from mlxtend.frequent_patterns import apriori
apriori(df, min_support=0.5,use_colnames=True)

# FP-Growth 알고리즘
# df 전처리는 동일
%%time
from mlxtend.frequent_patterns import fpgrowth

fpgrowth(df, min_support=0.5, use_colnames=True)

association = fpgroth(df, min_support =0.1, use_colnames=True)
assotication_rules(association, metric = 'confidence', min_threshold=0.5, support_only=False)
```



Rule기반 단점

- 메모리, 시간을 많이 잡아먹는다.

- 생성되는 규칙이 굉장히 많아서 막상 적용하기 힘들다.

- aprioiri 알고리즘 같은 경우는 데이터셋 처음 받아봤을 때, 연관있는지 시각적으로 의미파악하는데에 많이 사용임. 
- 컨텐츠기반, 협업필터링 기반의 알고리즘, 딥러닝 기반알고리즘이 성능이 좋아서 해당 알고리즘을 많이 사용함.



